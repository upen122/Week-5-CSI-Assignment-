
# ðŸš€ Azure Data Factory Assignment â€“ CSI Internship 2025

This project demonstrates four practical data integration tasks using **Azure Data Factory**. Each task includes detailed pipeline design, screenshots, triggers, and explanations.

---

## âœ… Task 1: Export SQL Data to CSV, Parquet, and Avro

### ðŸ” Objective

Export data from SQL tables (`Customers`, `Products`) to three formats: CSV, Parquet, and Avro.

### ðŸ§± Pipeline Overview

* 6 Copy activities:

  * 3 for `Customers`: CSV, Parquet, Avro
  * 3 for `Products`: CSV, Parquet, Avro
* Sink: Azure Blob Storage

### ðŸ“¸ Screenshots

### Pipeline :

![Screenshots](Screenshots/All_Pipeline/ExportCustomerProductToFormat.png)

---

## âœ… Task 2: Configure Schedule and Event Triggers

### ðŸ” Objective

Automate the pipeline from Task 1 using:

* A **Schedule Trigger** (runs daily at 9 AM IST)
* An **Event Trigger** (fires when `.txt` files are uploaded to Blob)

### âš™ï¸ Trigger Setup

* **Schedule Trigger:** `DailyExportTrigger`
* **Event Trigger:** `BlobEventTrigger` (Event Grid based)

### ðŸ“¸ Screenshots

> *(Add these under `/screenshots/triggers/`)*

* `schedule_trigger.png` â€“ Setup of daily trigger
* `event_trigger_register.png` â€“ Event Grid registration view
* `trigger_pipeline_binding.png` â€“ Pipeline linked to trigger
* `trigger_run_history.png` â€“ Proof of trigger execution

---

## âœ… Task 3: Copy All Tables from One Database to Another

### ðŸ” Objective

Replicate all base tables from `customerdb` to `customerdb_copy`.

### âš™ï¸ Key Components

* Lookup: Gets list of all base tables
* ForEach: Iterates over tables
* Copy Activity: Dynamically uses table names
* Parameters: Used in source and sink datasets

### ðŸ“¸ Screenshots

> *(Add these under `/screenshots/full_db_copy/`)*

* `lookup_tables_activity.png` â€“ `INFORMATION_SCHEMA.TABLES` lookup
* `foreach_loop_all_tables.png` â€“ ForEach config
* `dynamic_datasets_all_tables.png` â€“ Parameterized source/sink datasets
* `destination_db_verify.png` â€“ Destination tables seen in SSMS or Query Editor

---

## âœ… Task 4: Selective Copy (Specific Tables and Columns)

### ðŸ” Objective

Use a JSON config file to copy **specific tables and columns** only (e.g., `Customers` with only `CustomerID`, `Name`, etc.)

### âš™ï¸ How It Works

* `config.json` stored in Blob
* Dataset reads JSON config
* ForEach iterates through config rows
* SQL query is dynamically built with SELECT column list

### ðŸ“¸ Screenshots

> *(Add these under `/screenshots/selective_copy/`)*

* `config_json_blob.png` â€“ JSON file stored in Blob
* `json_dataset.png` â€“ Dataset pointing to JSON file
* `pipeline_selective_copy.png` â€“ Full pipeline showing dynamic query
* `destination_verify_selective.png` â€“ Destination table preview

---

## ðŸ§  Optional: Additional ADF Components

> *(Useful if shown in your pipeline)*

### ðŸ“¸ Screenshots

* `integration_runtime.png` â€“ Auto or SHIR used
* `linked_services.png` â€“ SQL + Blob linked services
* `monitor_pipeline_runs.png` â€“ Pipeline execution history tab

---

## ðŸ“ Folder Structure (Recommendation)

```bash
â”œâ”€â”€ README.md
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ ExportCustomerProductToFormats.json
â”‚   â”œâ”€â”€ FullDBCopyPipeline.json
â”‚   â”œâ”€â”€ SelectiveCopyPipeline.json
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ export_formats/
â”‚   â”œâ”€â”€ triggers/
â”‚   â”œâ”€â”€ full_db_copy/
â”‚   â”œâ”€â”€ selective_copy/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.json
```

---

## ðŸ”š Final Note

> Every pipeline includes:

* JSON definition
* Screenshots
* Clear explanation
* Use of ADF best practices like parameterization, triggers, modular pipelines.

ðŸ“Œ **This project demonstrates real-world skills in Azure Data Factory.**
